% TODO

% BRIEF REPETITION OF WHAT WE DID
% BRIEF REPETITION OF CONCLUSIONS BASED ON PLOTS

In our project, we investigated how stencil code implementations based on different GPU programming paradigms, i.e. OpenMP, OpenACC, and CUDA compare to each other in terms of performance.
Moreover, we compared these implementations against a parallel stencil code implementation targeted for multicore CPUs, and examined if running computations on the CPU and GPU concurrently can boost performance.
We found that due to the difference in performance between the OpenMP, OpenACC and CUDA GPU implementations, the amount of computations that has to be offloaded to the CPU, in order to improve performance, varies greatly.
In fact, while implementing the algorithm in CUDA is not straightforward, the hand-optimized version exhibits excellent performance, to the point where very little slices can be kept on the CPU without causing slowdown.
Meanwhile, the OpenMP and OpenACC version reach this point much later.
While in theory, and also according to (\cref{fig:time_vs_splitting_z_slices_256,fig:time_vs_splitting_z_slices_512,fig:time_vs_splitting_z_slices_1024}), there is scope for speed-up on all three versions, and even more so on the the OpenMP and OpenACC versions, due to their GPU implementations not being as optimised as the CUDA version, we see no performance gain in these cases. 

\vfill